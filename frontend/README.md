## 1. Papel do Frontend no Projeto

O frontend existe para:

- Permitir que um usu√°rio fa√ßa perguntas de forma visual
- Enviar essas perguntas para a API principal (`agent`)
- Exibir a resposta retornada, seja ela do LLM ou de uma tool

Toda a intelig√™ncia est√° na API. O frontend apenas consome.

---

## 2. Conex√£o com a API

```python
API_URL = "http://agent-api:8080/ask"
```

- Define o endere√ßo da API principal
- O nome `agent-api` √© resolvido via Docker Compose
- Toda pergunta do usu√°rio √© enviada para essa rota

O frontend n√£o conhece agentes, grafo ou ferramentas ‚Äî apenas essa URL.

---

## 3. Configura√ß√£o da P√°gina

```python
st.set_page_config(
    page_title="Artifact Case Chat",
    page_icon="ü§ñ",
    layout="centered",
)
```

- Define t√≠tulo, √≠cone e layout da aplica√ß√£o
- Essa configura√ß√£o roda uma √∫nica vez no carregamento

Em seguida, o t√≠tulo principal da interface √© exibido.

---

## 4. Controle de Estado da Conversa

```python
if "messages" not in st.session_state:
    st.session_state.messages = []
```

- Usa o `session_state` do Streamlit para manter o hist√≥rico
- Sem isso, a conversa seria perdida a cada intera√ß√£o

Cada mensagem √© armazenada com:

- `role`: user ou assistant
- `content`: texto exibido no chat

---

## 5. Renderiza√ß√£o do Hist√≥rico

```python
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
```

- Reexibe todo o hist√≥rico da conversa
- Garante que o chat pare√ßa cont√≠nuo para o usu√°rio

---

## 6. Entrada do Usu√°rio

```python
user_input = st.chat_input("Digite sua pergunta...")
```

- Campo de input no formato de chat
- Retorna valor apenas quando o usu√°rio envia a mensagem

Quando h√° entrada, o fluxo da conversa come√ßa.

---

## 7. Envio da Pergunta para a API

Ap√≥s o usu√°rio enviar a pergunta:

- A mensagem √© adicionada ao hist√≥rico
- A pergunta √© exibida imediatamente no chat
- A API √© chamada via `requests.post`

```python
response = requests.post(
    API_URL,
    json={"question": user_input},
    timeout=60,
)
```

O frontend apenas envia o texto ‚Äî nenhuma interpreta√ß√£o acontece aqui.

---

## 8. Tratamento da Resposta

O frontend interpreta a resposta apenas pelo campo `type`:

- **`llm_answer`** ‚Üí resposta direta do modelo
- **`calculation`** ‚Üí resultado retornado por uma tool

Com base nisso, o texto final exibido √© escolhido.

Caso a API retorne algo inesperado ou vazio, mensagens de fallback s√£o usadas para evitar respostas quebradas na UI.

---

## 9. Tratamento de Erros

```python
except Exception as e:
    answer = f"Erro ao chamar a API: {e}"
```

- Qualquer erro de rede ou timeout √© capturado
- O erro √© exibido de forma clara para o usu√°rio

Isso evita que a interface quebre silenciosamente.

---

## 10. Exibi√ß√£o da Resposta

Por fim:

- A resposta √© adicionada ao hist√≥rico
- O texto √© renderizado como mensagem do assistente

Isso fecha o ciclo da intera√ß√£o.

---

## 11. Resumo da L√≥gica

O frontend:

- Mant√©m o estado da conversa
- Envia perguntas para a API
- Interpreta apenas o tipo da resposta
- Exibe o resultado para o usu√°rio

Nada mais que isso ‚Äî simples, previs√≠vel e f√°ci